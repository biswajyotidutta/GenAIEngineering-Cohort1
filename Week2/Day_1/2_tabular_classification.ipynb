{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66903d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install tabpfn #pip install \"tabpfn @ git+https://github.com/PriorLabs/TabPFN.git\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014aca45",
   "metadata": {},
   "source": [
    "# Setting Up Data Science Environment for Classification\n",
    "\n",
    "This code sets up a Python environment for a classification task, specifically preparing to work with the breast cancer dataset. Here's what each import provides:\n",
    "\n",
    "\n",
    "### Machine Learning Framework\n",
    "- `load_breast_cancer`: A function to load the breast cancer Wisconsin dataset, a common benchmark for binary classification\n",
    "  - Features are computed from a digitized image of a fine needle aspirate of a breast mass\n",
    "  - The dataset includes 569 samples with 30 features\n",
    "  - The target variable indicates whether a tumor is malignant or benign\n",
    "\n",
    "- `accuracy_score` and `roc_auc_score`: Metrics for evaluating classification models\n",
    "  - Accuracy: The proportion of correct predictions\n",
    "  - ROC-AUC: Area under the Receiver Operating Characteristic curve, measuring the model's ability to discriminate between classes\n",
    "\n",
    "- `train_test_split`: A function to split datasets into random train and test subsets for model validation\n",
    "\n",
    "This code prepares the environment for building and evaluating a classification model, likely using TabPFN (based on your previous pip install) as the modeling approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f6aa040",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix, \n",
    "    classification_report, \n",
    "    precision_score, \n",
    "    recall_score, \n",
    "    f1_score, \n",
    "    roc_curve, \n",
    "    roc_auc_score\n",
    ")\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cbd5f8",
   "metadata": {},
   "source": [
    "# Load the breast cancer dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84b7d0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X, y = load_breast_cancer(return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21770ae0",
   "metadata": {},
   "source": [
    "# Get the feature names and target names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf78256d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cancer = load_breast_cancer()\n",
    "feature_names = cancer.feature_names\n",
    "target_names = cancer.target_names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317592e1",
   "metadata": {},
   "source": [
    "# Create a DataFrame for easier exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33818ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame(X, columns=feature_names)\n",
    "df['target'] = y\n",
    "df['diagnosis'] = [target_names[val] for val in y]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e5b3a3",
   "metadata": {},
   "source": [
    "# Basic dataset information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007808d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Dataset Shape:\", X.shape)\n",
    "print(\"Number of Features:\", X.shape[1])\n",
    "print(\"Number of Samples:\", X.shape[0])\n",
    "print(\"\\nClass Distribution:\")\n",
    "print(df['diagnosis'].value_counts())\n",
    "print(\"\\nClass Distribution (%):\")\n",
    "print(df['diagnosis'].value_counts(normalize=True).round(3) * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8485b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows of the dataset\n",
    "print(\"\\nFirst 5 rows of the dataset:\")\n",
    "print(df.head())\n",
    "\n",
    "# Statistical summary of features\n",
    "print(\"\\nStatistical Summary of Features:\")\n",
    "print(df.describe().T)\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing Values:\")\n",
    "print(df.isnull().sum().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccda078e",
   "metadata": {},
   "source": [
    "# Visualize the correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc5dcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(16, 14))\n",
    "correlation_matrix = df.drop('diagnosis', axis=1).corr()\n",
    "mask = np.triu(correlation_matrix)\n",
    "sns.heatmap(correlation_matrix, annot=False, mask=mask, cmap='coolwarm', linewidths=0.5)\n",
    "plt.title('Feature Correlation Matrix', fontsize=15)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Boxplots for comparing feature distributions between classes\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, feature in enumerate(feature_names[:5]):  # Just the first 5 features for clarity\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    sns.boxplot(x='diagnosis', y=feature, data=df)\n",
    "    plt.title(f'{feature} by Diagnosis')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Distribution of a few key features\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, feature in enumerate(feature_names[:5]):  # Just the first 5 features\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    sns.histplot(df[feature], kde=True, bins=30)\n",
    "    plt.title(f'Distribution of {feature}')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a779af",
   "metadata": {},
   "source": [
    "# Boxplots for comparing feature distributions between classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccf60e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, feature in enumerate(feature_names[:5]):  # Just the first 5 features for clarity\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    sns.boxplot(x='diagnosis', y=feature, data=df)\n",
    "    plt.title(f'{feature} by Diagnosis')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6df9f12",
   "metadata": {},
   "source": [
    "# Distribution of a few key features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16b0b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "for i, feature in enumerate(feature_names[:5]):  # Just the first 5 features\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    sns.histplot(df[feature], kde=True, bins=30)\n",
    "    plt.title(f'Distribution of {feature}')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ef9a76",
   "metadata": {},
   "source": [
    "# Using TabPFN for Breast Cancer Classification\n",
    "\n",
    "This code imports the TabPFN classifier and loads the breast cancer dataset for a classification task:\n",
    "\n",
    "### TabPFN Import\n",
    "- `TabPFNClassifier`: A specialized classifier from the TabPFN library that uses Prior-Data Fitted Networks\n",
    "  - TabPFN is designed specifically for tabular data\n",
    "  - It leverages transformer-based architectures pre-trained on synthetic tabular datasets\n",
    "  - The model requires minimal hyperparameter tuning and often performs well out-of-the-box\n",
    "\n",
    "### Dataset Loading\n",
    "- `load_breast_cancer(return_X_y=True)`: Loads the breast cancer Wisconsin dataset as NumPy arrays\n",
    "  - `X`: Features matrix with 569 samples and 30 features (measurements from digitized images)\n",
    "  - `y`: Target vector with binary values indicating benign (0) or malignant (1) tumors\n",
    "  - The `return_X_y=True` parameter specifies that the function should return the data and target as separate arrays rather than as a Bunch object\n",
    "\n",
    "This setup forms the foundation for applying the TabPFN classifier to predict breast cancer diagnoses based on the provided features. TabPFN is particularly well-suited for this type of tabular classification task with a moderate number of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1252d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabpfn import TabPFNClassifier\n",
    "\n",
    "# Load data\n",
    "X, y = load_breast_cancer(return_X_y=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feaeb143",
   "metadata": {},
   "source": [
    "# Splitting Data for Classification Model Evaluation\n",
    "\n",
    "\n",
    "This code divides the breast cancer dataset into training and testing sets using scikit-learn's `train_test_split` function:\n",
    "\n",
    "### Parameters Explained:\n",
    "- `X`: The feature matrix containing 30 features for each sample\n",
    "- `y`: The target vector with binary classification labels (0 for benign, 1 for malignant)\n",
    "- `test_size=0.5`: Allocates 50% of the data for testing and 50% for training\n",
    "  - This is a larger test set than the typical 20-30%, which might be chosen to better evaluate model performance\n",
    "- `random_state=42`: Sets a specific random seed for reproducibility\n",
    "  - Using a fixed random state ensures that the split will be the same each time the code runs\n",
    "  - The value 42 is commonly used as a default in data science (a reference to \"The Hitchhiker's Guide to the Galaxy\")\n",
    "\n",
    "### Result:\n",
    "- `X_train`: Features for training the model (569 × 0.5 = ~284 samples)\n",
    "- `X_test`: Features for evaluating the model (~284 samples)\n",
    "- `y_train`: Target labels for the training set\n",
    "- `y_test`: Target labels for the test set\n",
    "\n",
    "This even split allows for robust evaluation of the TabPFN classifier's performance on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9de948",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804df739",
   "metadata": {},
   "source": [
    "# Training the TabPFN Classifier\n",
    "\n",
    "This code initializes and trains a TabPFN classifier on the breast cancer dataset:\n",
    "\n",
    "### Model Initialization\n",
    "- `TabPFNClassifier()`: Creates an instance of the TabPFN classifier with default parameters\n",
    "  - TabPFN is a \"Prior-Data Fitted Network\" specifically designed for tabular data\n",
    "  - Unlike traditional ML models, TabPFN comes pre-trained on synthetic tabular data\n",
    "  - The default settings typically work well without extensive hyperparameter tuning\n",
    "\n",
    "### Model Training\n",
    "- `clf.fit(X_train, y_train)`: Trains the classifier on the training data\n",
    "  - `X_train`: Feature matrix with ~284 samples and 30 features\n",
    "  - `y_train`: Target vector with binary labels (benign/malignant)\n",
    "  - TabPFN's training process is generally faster than traditional ML models as it leverages transfer learning\n",
    "  - The model adapts its pre-trained knowledge to the specific patterns in the breast cancer dataset\n",
    "\n",
    "TabPFN typically requires less data for effective training compared to models that start from scratch, making it well-suited for medical datasets like this one where labeled data might be limited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43553e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a classifier\n",
    "clf = TabPFNClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329c0ed5",
   "metadata": {},
   "source": [
    "# Making Predictions and Evaluating Performance\n",
    "\n",
    "This code evaluates the TabPFN classifier by generating predictions and calculating the ROC AUC score:\n",
    "\n",
    "### Prediction Generation\n",
    "- `clf.predict_proba(X_test)`: Generates probability predictions for each class\n",
    "  - Returns a 2D array of shape (n_samples, n_classes) = (~284 samples, 2 classes)\n",
    "  - Each row represents one test sample\n",
    "  - Each column represents the probability of belonging to a class (0 or 1)\n",
    "\n",
    "### Performance Evaluation\n",
    "- `prediction_probabilities[:, 1]`: Extracts only the probabilities for the positive class (malignant)\n",
    "  - The second column (index 1) contains probabilities for the positive class\n",
    "\n",
    "- `roc_auc_score(y_test, prediction_probabilities[:, 1])`: Calculates the ROC AUC metric\n",
    "  - ROC (Receiver Operating Characteristic) curve plots the true positive rate against the false positive rate\n",
    "  - AUC (Area Under Curve) measures the classifier's ability to distinguish between classes\n",
    "  - Values range from 0 to 1, where:\n",
    "    - 1.0 represents a perfect classifier\n",
    "    - 0.5 represents a random classifier\n",
    "    - Values above 0.8 are generally considered good\n",
    "    - Values above 0.9 are considered excellent\n",
    "\n",
    "This evaluation helps assess how well the TabPFN model distinguishes between benign and malignant tumors based on the provided features, which is crucial for medical diagnostic applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78e553d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict probabilities\n",
    "prediction_probabilities = clf.predict_proba(X_test)\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, prediction_probabilities[:, 1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bd1784",
   "metadata": {},
   "source": [
    "# Predicting Class Labels and Evaluating Accuracy\n",
    "\n",
    "\n",
    "This code produces class predictions and evaluates the model's accuracy:\n",
    "\n",
    "### Prediction Generation\n",
    "- `clf.predict(X_test)`: Generates class label predictions for the test data\n",
    "  - Unlike `predict_proba()` which returns probabilities, this method returns the actual predicted class labels\n",
    "  - Returns a 1D array of shape (n_samples,) with values 0 (benign) or 1 (malignant)\n",
    "  - Internally, the model assigns the class with the highest probability to each sample\n",
    "\n",
    "### Performance Evaluation\n",
    "- `accuracy_score(y_test, predictions)`: Calculates the proportion of correct predictions\n",
    "  - Compares the predicted labels (`predictions`) with the true labels (`y_test`)\n",
    "  - Returns a value between 0 and 1, where:\n",
    "    - 1.0 means all predictions are correct\n",
    "    - 0.0 means all predictions are incorrect\n",
    "  - Formula: (Number of correct predictions) / (Total number of predictions)\n",
    "\n",
    "Accuracy is a straightforward metric for classification tasks, representing the percentage of samples correctly classified. For breast cancer diagnosis, high accuracy is important, but the ROC AUC score (calculated in the previous step) provides additional insight into the model's ability to distinguish between the classes, which is particularly valuable in medical contexts where false negatives can have serious consequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7492bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict labels\n",
    "predictions = clf.predict(X_test)\n",
    "print(\"Accuracy\", accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5722738",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36428e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, predictions)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Benign', 'Malignant'], \n",
    "            yticklabels=['Benign', 'Malignant'])\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9cf3cb",
   "metadata": {},
   "source": [
    "# 3. Classification Report, Individual Metrics and RoC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc15be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, predictions, \n",
    "                           target_names=['Benign', 'Malignant']))\n",
    "\n",
    "\n",
    "print(\"\\nKey Metrics:\")\n",
    "print(f\"Accuracy:  {accuracy_score(y_test, predictions):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, predictions):.4f}\")\n",
    "print(f\"Recall:    {recall_score(y_test, predictions):.4f}\")\n",
    "print(f\"F1 Score:  {f1_score(y_test, predictions):.4f}\")\n",
    "print(f\"ROC AUC:   {roc_auc_score(y_test, prediction_probabilities[:, 1]):.4f}\")\n",
    "\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test, prediction_probabilities[:, 1])\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f'ROC (AUC = {roc_auc_score(y_test, prediction_probabilities[:, 1]):.4f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae71a9a",
   "metadata": {},
   "source": [
    "# Installing and Using AutoTabPFN\n",
    "\n",
    "This code enhances the TabPFN implementation with automatic hyperparameter optimization:\n",
    "\n",
    "### Package Installation\n",
    "- `hyperopt`: A Python library for serial and parallel optimization over awkward search spaces\n",
    "- `tabpfn-extensions`: Extended functionality for TabPFN, including automated optimization tools\n",
    "- The commented portion shows how you could alternatively clone the repository directly\n",
    "\n",
    "### AutoTabPFN Setup\n",
    "- `AutoTabPFNClassifier`: An enhanced version of TabPFN that performs automatic tuning and ensemble creation\n",
    "  - Combines multiple TabPFN models with optimized configurations\n",
    "  - Uses Bayesian optimization via hyperopt to find optimal hyperparameters\n",
    "\n",
    "### Configuration Parameters\n",
    "- `max_time=120`: Limits the tuning process to 120 seconds (2 minutes)\n",
    "  - The optimizer will try to find the best configuration within this time constraint\n",
    "  - Longer times generally lead to better results but with diminishing returns\n",
    "- `device=\"cpu\"`: Specifies that computations should run on the CPU\n",
    "  - Alternative would be \"cuda\" for GPU acceleration if available\n",
    "\n",
    "### Training Process\n",
    "- `clf.fit(X_train, y_train)`: Trains the optimized ensemble model\n",
    "  - During this process, AutoTabPFN will:\n",
    "    1. Try different TabPFN configurations\n",
    "    2. Evaluate their performance\n",
    "    3. Select the best performing models\n",
    "    4. Create an ensemble of these models\n",
    "\n",
    "AutoTabPFN typically provides better performance than the base TabPFN model by leveraging ensemble techniques and hyperparameter optimization, though at the cost of longer training times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16831a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install hyperopt tabpfn-extensions #git clone https://github.com/priorlabs/tabpfn-extensions.git\n",
    "\n",
    "from tabpfn_extensions.post_hoc_ensembles.sklearn_interface import AutoTabPFNClassifier\n",
    "\n",
    "clf = AutoTabPFNClassifier(max_time=120, device=\"cpu\") # 120 seconds tuning time\n",
    "clf.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8690ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.predict(X_test)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9947e64a",
   "metadata": {},
   "source": [
    "# Saving and Loading the TabPFN Model\n",
    "\n",
    "Here's the code to save your trained TabPFN model and then load it back:\n",
    "\n",
    "\n",
    "1. **Saving the Model**:\n",
    "   - Uses Python's `pickle` module to serialize the model object\n",
    "   - The `'wb'` flag opens the file in binary write mode\n",
    "   - All model parameters and state are preserved in the file\n",
    "\n",
    "2. **Loading the Model**:\n",
    "   - Uses `pickle.load()` to deserialize the model from the file\n",
    "   - The `'rb'` flag opens the file in binary read mode\n",
    "   - The loaded model is stored in `loaded_clf`\n",
    "\n",
    "3. **Important Considerations**:\n",
    "   - Make sure the same version of TabPFN is used when loading the model\n",
    "   - The pickle format is Python-specific and not cross-language compatible\n",
    "   - For larger models, consider using joblib instead of pickle for better handling of large NumPy arrays\n",
    "\n",
    "This approach works well for TabPFN models and allows you to reuse your trained model without having to retrain it each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae630b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "# After training your model with clf.fit(X_train, y_train)\n",
    "\n",
    "# 1. Save the trained model to a file\n",
    "model_filename = 'tabpfn_breast_cancer_model.pkl'\n",
    "with open(model_filename, 'wb') as file:\n",
    "    pickle.dump(clf, file)\n",
    "print(f\"Model saved to {model_filename}\")\n",
    "\n",
    "# 2. Later, to load the model from the file\n",
    "if os.path.exists(model_filename):\n",
    "    with open(model_filename, 'rb') as file:\n",
    "        loaded_clf = pickle.load(file)\n",
    "    print(f\"Model loaded from {model_filename}\")\n",
    "    \n",
    "    # Verify the loaded model works correctly\n",
    "    test_predictions = loaded_clf.predict(X_test)\n",
    "    test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "    print(f\"Loaded model accuracy: {test_accuracy:.4f}\")\n",
    "else:\n",
    "    print(f\"Model file {model_filename} not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd764f3",
   "metadata": {},
   "source": [
    "1. **Loads the saved model** using pickle\n",
    "2. **Handles both single and multiple samples** by checking the input shape\n",
    "3. **Returns a dictionary with comprehensive prediction information**:\n",
    "   - Class labels (0/1)\n",
    "   - Full probability matrix for all classes\n",
    "   - Probability for the positive class only (simplified access)\n",
    "4. **Includes error handling** for common issues like missing files or data format problems\n",
    "5. **Provides example usage** for both single and batch prediction scenarios\n",
    "\n",
    "You can easily incorporate this function into any application that needs to use your trained TabPFN model for breast cancer prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b868b5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_tabpfn(input_data, model_path='tabpfn_breast_cancer_model.pkl'):\n",
    "   \"\"\"\n",
    "   Load a saved TabPFN model and make predictions for given input data.\n",
    "   \n",
    "   Parameters:\n",
    "   -----------\n",
    "   input_data : array-like\n",
    "       Input features for prediction, shape should match training data.\n",
    "       Can be a single sample (1D array) or multiple samples (2D array).\n",
    "   model_path : str, default='tabpfn_breast_cancer_model.pkl'\n",
    "       Path to the saved model file.\n",
    "   \n",
    "   Returns:\n",
    "   --------\n",
    "   dict: A dictionary containing:\n",
    "       - 'predictions': Class labels (0/1)\n",
    "       - 'probabilities': Probability estimates for each class\n",
    "       - 'positive_proba': Probability of the positive class (class 1)\n",
    "   \n",
    "   Raises:\n",
    "   -------\n",
    "   FileNotFoundError: If the model file doesn't exist\n",
    "   ValueError: If there's an issue with the input data format\n",
    "   \"\"\"\n",
    "   import pickle\n",
    "   import numpy as np\n",
    "   import os\n",
    "   \n",
    "   # Check if model file exists\n",
    "   if not os.path.exists(model_path):\n",
    "       raise FileNotFoundError(f\"Model file not found: {model_path}\")\n",
    "   \n",
    "   # Load the model\n",
    "   try:\n",
    "       with open(model_path, 'rb') as file:\n",
    "           model = pickle.load(file)\n",
    "       print(f\"Model successfully loaded from {model_path}\")\n",
    "   except Exception as e:\n",
    "       raise Exception(f\"Error loading model: {str(e)}\")\n",
    "   \n",
    "   # Ensure input is in the right format\n",
    "   input_data = np.asarray(input_data)\n",
    "   if input_data.ndim == 1:\n",
    "       # Single sample - reshape to 2D array\n",
    "       input_data = input_data.reshape(1, -1)\n",
    "   \n",
    "   # Make predictions\n",
    "   try:\n",
    "       predictions = model.predict(input_data)\n",
    "       probabilities = model.predict_proba(input_data)\n",
    "       positive_class_proba = probabilities[:, 1]  # Probability of class 1 (usually positive class)\n",
    "       \n",
    "       return {\n",
    "           'predictions': predictions,\n",
    "           'probabilities': probabilities,\n",
    "           'positive_proba': positive_class_proba\n",
    "       }\n",
    "   except Exception as e:\n",
    "       raise ValueError(f\"Error during prediction: {str(e)}\")\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "   # Example for a single sample\n",
    "   # Replace with your actual test data\n",
    "   sample = X_test[0]  # Single test instance\n",
    "   \n",
    "   result = predict_with_tabpfn(sample)\n",
    "   print(f\"Prediction: {'Malignant' if result['predictions'][0] == 1 else 'Benign'}\")\n",
    "   print(f\"Confidence: {result['positive_proba'][0]:.4f}\")\n",
    "   \n",
    "   # Example for multiple samples\n",
    "   samples = X_test[:5]  # First 5 test instances\n",
    "   \n",
    "   batch_result = predict_with_tabpfn(samples)\n",
    "   for i, (pred, prob) in enumerate(zip(batch_result['predictions'], batch_result['positive_proba'])):\n",
    "       print(f\"Sample {i+1}: {'Malignant' if pred == 1 else 'Benign'} (Confidence: {prob:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e141f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9339662",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "week2_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
