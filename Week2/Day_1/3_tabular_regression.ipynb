{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66903d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install tabpfn #pip install \"tabpfn @ git+https://github.com/PriorLabs/TabPFN.git\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014aca45",
   "metadata": {},
   "source": [
    "# Setting Up Data Science Environment for Regression\n",
    "\n",
    "\n",
    "This code imports essential tools for working with public datasets and evaluating regression models:\n",
    "\n",
    "### Data Acquisition\n",
    "- `fetch_openml`: Fetches datasets from the OpenML repository, which hosts thousands of public datasets\n",
    "  - Unlike fixed scikit-learn datasets, this allows access to a wide variety of real-world data\n",
    "  - Datasets can be specified by name or ID number\n",
    "  - Example: `fetch_openml(name='boston', version=1)` or `fetch_openml(data_id=42)`\n",
    "\n",
    "### Model Evaluation\n",
    "- `mean_squared_error`: Calculates the average squared difference between predicted and actual values\n",
    "  - Lower values indicate better model performance\n",
    "  - Formula: MSE = (1/n) * Σ(y_true - y_pred)²\n",
    "  - Units are squared units of the target variable\n",
    "\n",
    "- `r2_score`: Coefficient of determination (R²)\n",
    "  - Measures the proportion of variance in the dependent variable predictable from the independent variables\n",
    "  - Range: 0 to 1, where 1 indicates perfect prediction\n",
    "  - Can be negative if the model is worse than a horizontal line\n",
    "\n",
    "### Data Splitting\n",
    "- `train_test_split`: Divides datasets into random training and testing subsets\n",
    "  - Essential for proper model validation\n",
    "  - Typical usage: `X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)`\n",
    "  - Parameters control split ratio, stratification, and randomization\n",
    "\n",
    "These tools are commonly used together in a regression workflow to fetch datasets, split the data appropriately, and evaluate model performance using standard metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6aa040",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cbd5f8",
   "metadata": {},
   "source": [
    "# Load the Boston Housing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b97fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = fetch_openml(data_id=531, as_frame=True)  # Boston Housing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21770ae0",
   "metadata": {},
   "source": [
    "# Get the feature names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf78256d",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names=list(data_dict.data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317592e1",
   "metadata": {},
   "source": [
    "# Create a DataFrame for easier exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33818ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = fetch_openml(data_id=531, as_frame=True) \n",
    "\n",
    "X = data_dict.data\n",
    "y = data_dict.target.astype(float)  # Ensure target is float for regression\n",
    "df = pd.DataFrame(X, columns=feature_names)\n",
    "df['MEDV'] = y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e5b3a3",
   "metadata": {},
   "source": [
    "# Basic dataset information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007808d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(\"\\nFeature Names:\")\n",
    "for i, name in enumerate(feature_names):\n",
    "    print(f\"{i+1}. {name}\")\n",
    "\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89eafa8f",
   "metadata": {},
   "source": [
    "# Statistical summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8485b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary\n",
    "print(\"\\nStatistical Summary:\")\n",
    "print(df.describe().T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccda078e",
   "metadata": {},
   "source": [
    "# Check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc5dcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = df.isnull().sum()\n",
    "print(\"\\nMissing Values:\")\n",
    "print(missing_values[missing_values > 0] if missing_values.sum() > 0 else \"No missing values\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a779af",
   "metadata": {},
   "source": [
    "# Target variable distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccf60e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df['MEDV'], kde=True, bins=30)\n",
    "plt.title('Distribution of House Prices (MEDV)')\n",
    "plt.xlabel('Median Value of Homes ($1000s)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6df9f12",
   "metadata": {},
   "source": [
    "# Print target statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16b0b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nTarget (MEDV) Statistics:\")\n",
    "print(df['MEDV'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9190df37",
   "metadata": {},
   "source": [
    "# Correlations with target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80de3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = df.corr()['MEDV'].sort_values(ascending=False)\n",
    "print(\"\\nCorrelations with Target (MEDV):\")\n",
    "print(correlations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3446df5",
   "metadata": {},
   "source": [
    "# Visualize correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0438c749",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(df.corr(), annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.xticks(rotation=45)\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c388f82",
   "metadata": {},
   "source": [
    "# Top correlated features with target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ef7273",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_corr_features = correlations.index[1:6]  # Excluding MEDV itself which has correlation 1.0\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, feature in enumerate(top_corr_features):\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    plt.scatter(df[feature], df['MEDV'], alpha=0.6)\n",
    "    plt.title(f'MEDV vs {feature} (corr: {correlations[feature]:.2f})')\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel('MEDV')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3385f75",
   "metadata": {},
   "source": [
    "# Pairplot of important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97650141",
   "metadata": {},
   "outputs": [],
   "source": [
    "important_features = list(top_corr_features) + ['MEDV']\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.pairplot(df[important_features], height=2.5)\n",
    "plt.suptitle('Pairplot of Important Features', y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2c8e66",
   "metadata": {},
   "source": [
    "# Check for Skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c27bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Check for Skewness\n",
    "df_numeric = df.select_dtypes(include=['number'])\n",
    "skewness = df_numeric.skew().sort_values(ascending=False)\n",
    "print(\"\\nSkewness of Features:\")\n",
    "print(skewness)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "skewness.plot(kind='bar')\n",
    "plt.title('Skewness of Features')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f38b510",
   "metadata": {},
   "source": [
    "# Outlier detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fdf483",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "for i, feature in enumerate(df_numeric.columns):\n",
    "    if i >= 9:  # Limit to 9 features for readability\n",
    "        break\n",
    "    plt.subplot(3, 3, i+1)\n",
    "    sns.boxplot(y=df[feature])\n",
    "    plt.title(f'Boxplot of {feature}')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e8f455",
   "metadata": {},
   "source": [
    "# Distribution of important feature variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3f4284",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "for i, feature in enumerate(feature_names):\n",
    "    if i >= 9:  # Limit to 9 features for readability\n",
    "        break\n",
    "    plt.subplot(3, 3, i+1)\n",
    "    sns.histplot(df[feature], kde=True)\n",
    "    plt.title(f'Distribution of {feature}')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ef9a76",
   "metadata": {},
   "source": [
    "# Using TabPFN for Regression on Boston Housing Data\n",
    "\n",
    "This code sets up a regression task using TabPFN on the Boston Housing dataset:\n",
    "\n",
    "### TabPFN for Regression\n",
    "- `TabPFNRegressor`: A specialized regression variant of TabPFN (Tabular Prior-Data Fitted Network)\n",
    "  - Unlike the classifier version, this is designed for predicting continuous values\n",
    "  - Leverages the same transformer-based architecture with pre-training on synthetic tabular data\n",
    "  - Typically requires minimal hyperparameter tuning for good performance\n",
    "\n",
    "### Data Loading\n",
    "- `fetch_openml(data_id=531, as_frame=True)`: Retrieves the Boston Housing dataset from OpenML\n",
    "  - `data_id=531`: Specifies the Boston Housing dataset by its unique identifier\n",
    "  - `as_frame=True`: Returns the data as a pandas DataFrame instead of a numpy array\n",
    "  - This dataset contains information about housing in Boston suburbs and is a classic benchmark for regression\n",
    "\n",
    "### Data Preparation\n",
    "- `X = df.data`: Extracts the feature matrix\n",
    "  - Contains attributes like CRIM (crime rate), ZN (proportion of residential land), INDUS (proportion of non-retail business acres), etc.\n",
    "- `y = df.target.astype(float)`: Extracts the target variable and ensures it's in float format\n",
    "  - The target is MEDV (Median value of owner-occupied homes in $1000s)\n",
    "  - Converting to float is important for regression tasks to ensure proper calculations\n",
    "\n",
    "This setup prepares for applying TabPFN's regression capabilities to predict housing prices based on neighborhood characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1252d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabpfn import TabPFNRegressor  \n",
    "\n",
    "# Load Boston Housing data\n",
    "df = fetch_openml(data_id=531, as_frame=True)  # Boston Housing dataset\n",
    "X = df.data\n",
    "y = df.target.astype(float)  # Ensure target is float for regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feaeb143",
   "metadata": {},
   "source": [
    "# Splitting Data for Regression Analysis\n",
    "\n",
    "\n",
    "### Function Parameters\n",
    "- `X`: Feature matrix containing housing attributes (like crime rate, number of rooms, etc.)\n",
    "- `y`: Target vector containing housing prices (MEDV)\n",
    "- `test_size=0.5`: Allocates 50% of the data for testing and 50% for training\n",
    "  - This is a larger test set than typical (usually 20-30%)\n",
    "  - A 50/50 split provides ample data for both training and thorough evaluation\n",
    "- `random_state=42`: Sets a specific random seed for reproducibility\n",
    "  - Ensures the same split will occur each time the code runs\n",
    "  - The value 42 is commonly used (a reference to \"The Hitchhiker's Guide to the Galaxy\")\n",
    "\n",
    "### Resulting Datasets\n",
    "- `X_train`: Features for training the model (approximately 253 samples)\n",
    "- `X_test`: Features for evaluating the model (approximately 253 samples)\n",
    "- `y_train`: Housing prices for the training set\n",
    "- `y_test`: Housing prices for the test set\n",
    "\n",
    "### Purpose\n",
    "This data split allows you to:\n",
    "1. Train the TabPFN regressor on one subset of the data\n",
    "2. Test its performance on unseen data to evaluate generalization\n",
    "3. Get a realistic estimate of how the model would perform on new housing data\n",
    "\n",
    "The equal split between training and testing provides a balanced assessment of the model's predictive capabilities for this regression task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9de948",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804df739",
   "metadata": {},
   "source": [
    "# Training the TabPFN Regressor\n",
    "\n",
    "This code initializes and trains a TabPFN regressor on the Boston Housing dataset:\n",
    "\n",
    "### Model Initialization\n",
    "- `TabPFNRegressor()`: Creates an instance of TabPFN's regression model with default parameters\n",
    "  - Unlike traditional regression models, TabPFN comes pre-trained on synthetic tabular data\n",
    "  - The default configuration typically works well without extensive hyperparameter tuning\n",
    "  - Optional parameters include N_ensemble_configurations (number of models in ensemble) and device (CPU/GPU)\n",
    "\n",
    "### Model Training\n",
    "- `regressor.fit(X_train, y_train)`: Adapts the regressor to the housing price prediction task\n",
    "  - `X_train`: Feature matrix containing ~253 samples with housing attributes\n",
    "  - `y_train`: Target vector containing corresponding housing prices (MEDV values)\n",
    "  - The training process is typically faster than traditional models as it leverages transfer learning\n",
    "  - TabPFN adapts its pre-trained knowledge to the specific patterns in the Boston Housing dataset\n",
    "\n",
    "### What Happens During Fitting\n",
    "During the `fit()` operation, TabPFN:\n",
    "1. Normalizes the input features internally\n",
    "2. Adapts its pre-trained transformer architecture to the regression task\n",
    "3. Optimizes for continuous value prediction rather than classification\n",
    "4. May create an ensemble of models if configured to do so\n",
    "\n",
    "TabPFN's approach is especially advantageous for tabular regression tasks like housing price prediction, often achieving competitive performance with minimal configuration and training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43553e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the regressor\n",
    "regressor = TabPFNRegressor()  \n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329c0ed5",
   "metadata": {},
   "source": [
    "# Making Predictions with TabPFN Regressor\n",
    "\n",
    "\n",
    "This code generates housing price predictions using the trained TabPFN regressor:\n",
    "\n",
    "### Prediction Process\n",
    "- `regressor.predict(X_test)`: Applies the trained model to make predictions on unseen test data\n",
    "  - Takes the feature matrix `X_test` as input\n",
    "  - Returns an array of predicted housing prices (MEDV values in $1000s)\n",
    "  - No probability values are returned since this is a regression task (unlike classification)\n",
    "\n",
    "### Behind the Scenes\n",
    "When you call `predict()`, TabPFN:\n",
    "1. Processes the input features through its transformer-based architecture\n",
    "2. Converts the network outputs to continuous values appropriate for the regression task\n",
    "3. Returns point estimates for each sample in the test set\n",
    "\n",
    "### Next Steps After Prediction\n",
    "After generating these predictions, you would typically:\n",
    "- Evaluate model performance using metrics like MSE, RMSE, or R²\n",
    "- Compare the predictions against actual values (y_test)\n",
    "- Visualize the predictions vs. actual values to identify patterns or areas for improvement\n",
    "\n",
    "TabPFN's unique approach often leads to competitive regression results with minimal configuration, making it an excellent choice for tabular regression tasks like housing price prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78e553d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test set\n",
    "predictions = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67cff1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bd1784",
   "metadata": {},
   "source": [
    "# Evaluating the TabPFN Regressor\n",
    "\n",
    "\n",
    "This code assesses the performance of the TabPFN regressor using two standard regression metrics:\n",
    "\n",
    "### Mean Squared Error (MSE)\n",
    "- `mean_squared_error(y_test, predictions)`: Calculates the average squared difference between predicted and actual housing prices\n",
    "  - Formula: MSE = (1/n) * Σ(y_true - y_pred)²\n",
    "  - Lower values indicate better model performance\n",
    "  - Units are squared dollars (in thousands), making it scale-dependent\n",
    "  - Penalizes larger errors more heavily due to the squaring operation\n",
    "  - Useful for comparing models on the same dataset\n",
    "\n",
    "### R² Score (Coefficient of Determination)\n",
    "- `r2_score(y_test, predictions)`: Measures the proportion of variance in housing prices that the model explains\n",
    "  - Formula: R² = 1 - (Σ(y_true - y_pred)² / Σ(y_true - y_mean)²)\n",
    "  - Scale-free metric ranging from -∞ to 1\n",
    "  - R² = 1 indicates perfect prediction\n",
    "  - R² = 0 indicates the model performs no better than simply predicting the mean value\n",
    "  - R² < 0 indicates the model performs worse than predicting the mean\n",
    "  - Generally, R² > 0.7 is considered good for real estate price prediction\n",
    "\n",
    "### Interpretation\n",
    "- These metrics together provide complementary insights:\n",
    "  - MSE gives an absolute measure of prediction error in squared units\n",
    "  - R² provides a relative measure of how well the model captures the variance in housing prices\n",
    "  - A good model should have low MSE and high R² values\n",
    "\n",
    "For the Boston Housing dataset, these metrics help assess how accurately TabPFN can predict home values based on neighborhood characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7492bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "r2 = r2_score(y_test, predictions)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"R² Score:\", r2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "week2_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
